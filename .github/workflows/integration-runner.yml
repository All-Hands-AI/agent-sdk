name: Run Integration Tests

on:
  pull_request:
    types: 
      - labeled
      - synchronize
  workflow_dispatch:
    inputs:
      reason:
        description: 'Reason for manual trigger'
        required: true
        default: ''
  schedule:
    - cron: '30 22 * * *'  # Runs at 10:30pm UTC every day

env:
  N_PROCESSES: 4 # Global configuration for number of parallel processes for evaluation

jobs:
  run-integration-tests:
    if: github.event.label.name == 'integration-test' || github.event_name == 'workflow_dispatch' || github.event_name == 'schedule'
    runs-on: blacksmith-4vcpu-ubuntu-2204
    permissions:
      contents: "read"
      id-token: "write"
      pull-requests: "write"
      issues: "write"
    strategy:
      matrix:
        python-version: ["3.12"]
        job-config:
          - name: "Claude Sonnet 4"
            run-suffix: "sonnet_run"
            llm-config:
              model: "litellm_proxy/anthropic/claude-sonnet-4-20250514"
          - name: "GPT-5 Mini"
            run-suffix: "gpt5_mini_run"
            llm-config:
              model: "litellm_proxy/openai/gpt-5-mini"
              temperature: 1.0
          - name: "DeepSeek Chat"
            run-suffix: "deepseek_run"
            llm-config:
              model: "litellm_proxy/deepseek/deepseek-chat"
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Install uv
        uses: astral-sh/setup-uv@v4
        with:
          version: "latest"
          python-version: ${{ matrix.python-version }}

      - name: Comment on PR if 'integration-test' label is present
        if: github.event_name == 'pull_request' && github.event.label.name == 'integration-test'
        uses: KeisukeYamashita/create-comment@v1
        with:
          unique: false
          comment: |
            Hi! I started running the integration tests on your PR. You will receive a comment with the results shortly.

      - name: Install Python dependencies using uv
        run: |
          uv sync --dev
          uv pip install pytest

      # Run integration test evaluation
      - name: Run integration test evaluation for ${{ matrix.job-config.name }}
        env:
          LLM_CONFIG: ${{ toJson(matrix.job-config.llm-config) }}
          LLM_API_KEY: ${{ secrets.LLM_API_KEY }}
          LLM_BASE_URL: ${{ secrets.LLM_BASE_URL }}
        run: |
          ./tests/integration/run_infer.sh "$LLM_CONFIG" "$LLM_API_KEY" "$LLM_BASE_URL" $N_PROCESSES '' '${{ matrix.job-config.run-suffix }}'

          # get integration tests report
          REPORT_FILE=$(find tests/integration/outputs/*${{ matrix.job-config.run-suffix }}* -name "report.md" -type f | head -n 1)
          echo "REPORT_FILE: $REPORT_FILE"
          if [ -f "$REPORT_FILE" ]; then
            echo "INTEGRATION_TEST_REPORT<<EOF" >> $GITHUB_ENV
            cat $REPORT_FILE >> $GITHUB_ENV
            echo >> $GITHUB_ENV
            echo "EOF" >> $GITHUB_ENV
          else
            echo "INTEGRATION_TEST_REPORT=No report file found" >> $GITHUB_ENV
          fi

      - name: Wait a little bit
        run: sleep 10





      - name: Create archive of evaluation outputs
        run: |
          TIMESTAMP=$(date +'%y-%m-%d-%H-%M')
          cd tests/integration/outputs  # Change to the outputs directory
          tar -czvf ../../../integration_tests_${{ matrix.job-config.run-suffix }}_${TIMESTAMP}.tar.gz *${{ matrix.job-config.run-suffix }}* # Include result directories for this model

      - name: Upload evaluation results as artifact
        uses: actions/upload-artifact@v4
        id: upload_results_artifact
        with:
          name: integration-test-outputs-${{ matrix.job-config.run-suffix }}-${{ github.run_id }}-${{ github.run_attempt }}
          path: integration_tests_${{ matrix.job-config.run-suffix }}_*.tar.gz

      - name: Save test results for consolidation
        run: |
          # Create a results summary file for this model
          mkdir -p test_results_summary
          cat > test_results_summary/${{ matrix.job-config.run-suffix }}_results.json << EOF
          {
            "model_name": "${{ matrix.job-config.name }}",
            "run_suffix": "${{ matrix.job-config.run-suffix }}",
            "test_report": $(echo '${{ env.INTEGRATION_TEST_REPORT }}' | jq -Rs .),
            "artifact_url": "${{ steps.upload_results_artifact.outputs.artifact-url }}",
            "status": "completed"
          }
          EOF

      - name: Upload test results summary
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ matrix.job-config.run-suffix }}
          path: test_results_summary/${{ matrix.job-config.run-suffix }}_results.json

  consolidate-results:
    needs: run-integration-tests
    if: always() && (github.event.label.name == 'integration-test' || github.event_name == 'workflow_dispatch' || github.event_name == 'schedule')
    runs-on: ubuntu-latest
    permissions:
      contents: "read"
      pull-requests: "write"
      issues: "write"
    steps:
      - name: Download all test results
        uses: actions/download-artifact@v4
        with:
          pattern: test-results-*
          merge-multiple: true
          path: all_results

      - name: Consolidate test results and create PR comment
        run: |
          # Set trigger information
          if [[ "${{ github.event_name }}" == "pull_request" ]]; then
            TRIGGER_TEXT="Pull Request (integration-test label on PR #${{ github.event.pull_request.number }})"
            PR_NUMBER="${{ github.event.pull_request.number }}"
          elif [[ "${{ github.event_name }}" == "workflow_dispatch" ]]; then
            TRIGGER_TEXT="Manual Trigger: ${{ github.event.inputs.reason }}"
            PR_NUMBER="9745"  # fallback issue number
          else
            TRIGGER_TEXT="Nightly Scheduled Run"
            PR_NUMBER="9745"  # fallback issue number
          fi

          # Initialize consolidated report
          cat > consolidated_report.md << 'EOF'
          # Integration Tests Report

          **Trigger:** TRIGGER_PLACEHOLDER
          **Commit:** ${{ github.sha }}
          **Timestamp:** $(date +'%Y-%m-%d %H:%M UTC')

          ## Test Results Summary

          | Model | Success Rate | Test Results | Artifact Link |
          |-------|--------------|--------------|---------------|
          EOF

          # Process each result file
          DETAILED_RESULTS=""
          TOTAL_MODELS=0

          echo "DEBUG: Looking for result files in all_results/"
          ls -la all_results/ || echo "DEBUG: all_results directory not found"
          echo "DEBUG: Found result files:"
          find all_results/ -name "*_results.json" -type f || echo "DEBUG: No result files found"

          for result_file in all_results/*_results.json; do
            echo "DEBUG: Processing file: $result_file"
            if [[ -f "$result_file" ]]; then
              echo "DEBUG: File exists, checking content:"
              cat "$result_file" || echo "DEBUG: Failed to read file"
              
              echo "DEBUG: Extracting JSON fields..."
              MODEL_NAME=$(jq -r '.model_name' "$result_file") || { echo "DEBUG: Failed to extract model_name"; exit 1; }
              echo "DEBUG: MODEL_NAME=$MODEL_NAME"
              
              RUN_SUFFIX=$(jq -r '.run_suffix' "$result_file") || { echo "DEBUG: Failed to extract run_suffix"; exit 1; }
              echo "DEBUG: RUN_SUFFIX=$RUN_SUFFIX"
              
              TEST_REPORT=$(jq -r '.test_report' "$result_file") || { echo "DEBUG: Failed to extract test_report"; exit 1; }
              echo "DEBUG: TEST_REPORT length: ${#TEST_REPORT}"
              
              ARTIFACT_URL=$(jq -r '.artifact_url' "$result_file") || { echo "DEBUG: Failed to extract artifact_url"; exit 1; }
              echo "DEBUG: ARTIFACT_URL=$ARTIFACT_URL"
              
              # Extract success rate from test report
              echo "DEBUG: Extracting success rate from test report..."
              SUCCESS_RATE=$(echo "$TEST_REPORT" | grep -oE "Success rate: [0-9]+\.[0-9]+%" | head -1)
              echo "DEBUG: Extracted SUCCESS_RATE=$SUCCESS_RATE"
              if [[ -z "$SUCCESS_RATE" ]]; then
                SUCCESS_RATE="N/A"
                echo "DEBUG: No success rate found, using N/A"
              fi
              
              # Add to summary table
              echo "DEBUG: Adding row to summary table..."
              echo "| $MODEL_NAME | $SUCCESS_RATE | See details below | [Download]($ARTIFACT_URL) |" >> consolidated_report.md || { echo "DEBUG: Failed to write to consolidated_report.md"; exit 1; }
              
              # Add to detailed results
              DETAILED_RESULTS="$DETAILED_RESULTS

          ### $MODEL_NAME
          \`\`\`
          $TEST_REPORT
          \`\`\`"
              
              ((TOTAL_MODELS++))
            fi
          done

          # Complete the report
          echo "DEBUG: Completing report with $TOTAL_MODELS models..."
          cat >> consolidated_report.md << EOF

          ## Detailed Results
          $DETAILED_RESULTS

          ---
          **Overall Status:** $TOTAL_MODELS models tested
          EOF

          echo "DEBUG: Report completed, checking content:"
          echo "DEBUG: Report file size: $(wc -c < consolidated_report.md) bytes"
          echo "DEBUG: Report preview:"
          head -20 consolidated_report.md

          # Replace placeholder with actual trigger text
          echo "DEBUG: Replacing trigger placeholder..."
          sed -i "s/TRIGGER_PLACEHOLDER/$TRIGGER_TEXT/" consolidated_report.md || { echo "DEBUG: Failed to replace trigger placeholder"; exit 1; }

          # Save PR number and comment content for next step
          echo "DEBUG: Saving environment variables..."
          echo "DEBUG: PR_NUMBER=$PR_NUMBER"
          echo "PR_NUMBER=$PR_NUMBER" >> $GITHUB_ENV || { echo "DEBUG: Failed to save PR_NUMBER"; exit 1; }
          echo "COMMENT_BODY<<EOF" >> $GITHUB_ENV || { echo "DEBUG: Failed to start COMMENT_BODY"; exit 1; }
          cat consolidated_report.md >> $GITHUB_ENV || { echo "DEBUG: Failed to save report content"; exit 1; }
          echo "EOF" >> $GITHUB_ENV || { echo "DEBUG: Failed to end COMMENT_BODY"; exit 1; }
          echo "DEBUG: Environment variables saved successfully"

      - name: Create consolidated PR comment
        uses: KeisukeYamashita/create-comment@v1
        with:
          number: ${{ env.PR_NUMBER }}
          unique: false
          comment: ${{ env.COMMENT_BODY }}

